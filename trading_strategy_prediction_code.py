# -*- coding: utf-8 -*-
"""Trading Strategy Prediction Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iVSmpKlgs1iOIjCKKrOrHxIh7FY9ubv3
"""

!pip3 install bitmex

import numpy as np
import pandas as pd
import bitmex
import json
import requests
import time
import math
import os.path
import xgboost as xgb
import datetime as dt
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score
from tqdm import tqdm_notebook
from datetime import timedelta, datetime
from dateutil import parser

import matplotlib.pyplot as plt
from itertools import cycle
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import seaborn as sns

from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score 
from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score, f1_score
from sklearn.preprocessing import MinMaxScaler

from plotly.offline import plot, iplot, init_notebook_mode
init_notebook_mode(connected=True)

bitmex_api_key = "NC_0TmtRCIeIuE52qx_W2Zjp"
bitmex_api_secret = "d8wM1lMbtZmyDiFBmXBozHnBpa6rXA_Wdre-Rk2gBVAr5i-t"
binsizes = {"1m": 1, "5m": 5, "1h": 60, "1d": 1440}
batch_size = 750
bitmex_client = bitmex.bitmex(test=False, api_key=bitmex_api_key, api_secret=bitmex_api_secret)
binSize='1h'
past_minute_data = bitmex_client.Trade.Trade_getBucketed(binSize=binSize, count=1000, symbol='XBTUSD', reverse=True)

def minutes_of_new_data(symbol, kline_size, data, source):
    if len(data) > 0:  old = parser.parse(data["timestamp"].iloc[-1])
    elif source == "bitmex": old = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']
    if source == "bitmex": new = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']
    return old, new

def get_all_bitmex(symbol, kline_size, save = False):
    filename = '%s-%s-data.csv' % (symbol, kline_size)
    if os.path.isfile(filename): data_df = pd.read_csv(filename)
    else: data_df = pd.DataFrame()
    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = "bitmex")
    delta_min = (newest_point - oldest_point).total_seconds()/60
    available_data = math.ceil(delta_min/binsizes[kline_size])
    rounds = math.ceil(available_data / batch_size)
    if rounds > 0:
        print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data in %d rounds.' % (delta_min, symbol, available_data, kline_size, rounds))
        for round_num in tqdm_notebook(range(rounds)):
            time.sleep(1)
            new_time = (oldest_point + timedelta(minutes = round_num * batch_size * binsizes[kline_size]))
            data = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]
            temp_df = pd.DataFrame(data)
            data_df = data_df.append(temp_df)
    data_df.set_index('timestamp', inplace=True)
    if save and rounds > 0: data_df.to_csv(filename)
    print('All caught up..!')
    return data_df

data_df = get_all_bitmex("XBTUSD", "1d", save=True)

#Loading dataset
data=pd.read_csv("/content/XBTUSD-1d-data.csv")

data.head()

data.tail()

data.shape

data.describe()

data.isnull().sum()

data['timestamp'] = pd.to_datetime(data.timestamp)
data.head()

print("Starting date: ",data.iloc[0][0])
print("Ending date: ", data.iloc[-1][0])
print("Duration: ", data.iloc[-1][0]-data.iloc[0][0])

#EDA
#Visualizing dataset for 2015
y_2015 = data.loc[(data['timestamp'] >= '2015-01-01')
                     & (data['timestamp'] < '2016-01-01')]

y_2015.drop(y_2015[['trades','volume','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

monthvise= y_2015.groupby(y_2015['timestamp'].dt.strftime('%B'))[['open','close']].mean()
new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 
             'September', 'October', 'November', 'December']
monthvise = monthvise.reindex(new_order, axis=0)
monthvise

fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['open'],
    name='Open Price',
    marker_color='crimson'
))
fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['close'],
    name='Close Price',
    marker_color='lightsalmon'
))

fig.update_layout(barmode='group', xaxis_tickangle=-45, 
                  title='Monthwise comparision between open and close price')
fig.show()

y_2015.groupby(y_2015['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_high = y_2015.groupby(data['timestamp'].dt.strftime('%B'))['high'].max()
monthvise_high = monthvise_high.reindex(new_order, axis=0)

monthvise_low = y_2015.groupby(y_2015['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_low = monthvise_low.reindex(new_order, axis=0)

fig = go.Figure()
fig.add_trace(go.Bar(
    x=monthvise_high.index,
    y=monthvise_high,
    name='high Price',
    marker_color='rgb(0, 153, 204)'
))
fig.add_trace(go.Bar(
    x=monthvise_low.index,
    y=monthvise_low,
    name='low Price',
    marker_color='rgb(255, 128, 0)'
))

fig.update_layout(barmode='group', 
                  title=' Monthwise High and Low price')
fig.show()

names = cycle(['Open Price','Close Price','High Price','Low Price'])

fig = px.line(y_2015, x=y_2015.timestamp, y=[y_2015['open'], y_2015['close'], 
                                          y_2015['high'], y_2015['low']],
             labels={'Timestamp': 'Timestamp','value':'Stock value'})
fig.update_layout(title_text=' Analysis chart', font_size=15, font_color='black',legend_title_text=' Parameters')
fig.for_each_trace(lambda t:  t.update(name = next(names)))
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)

fig.show()

#EDA
#Visualizing dataset for 2020
y_2020 = data.loc[(data['timestamp'] >= '2020-01-01')
                     & (data['timestamp'] < '2021-01-01')]

y_2020.drop(y_2020[['trades','volume','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

monthvise= y_2020.groupby(y_2020['timestamp'].dt.strftime('%B'))[['open','close']].mean()
new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 
             'September', 'October', 'November', 'December']
monthvise = monthvise.reindex(new_order, axis=0)
monthvise

fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['open'],
    name='Open Price',
    marker_color='crimson'
))
fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['close'],
    name='Close Price',
    marker_color='lightsalmon'
))

fig.update_layout(barmode='group', xaxis_tickangle=-45, 
                  title='Monthwise comparision between open and close price')
fig.show()

y_2020.groupby(y_2020['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_high = y_2020.groupby(data['timestamp'].dt.strftime('%B'))['high'].max()
monthvise_high = monthvise_high.reindex(new_order, axis=0)

monthvise_low = y_2020.groupby(y_2020['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_low = monthvise_low.reindex(new_order, axis=0)

fig = go.Figure()
fig.add_trace(go.Bar(
    x=monthvise_high.index,
    y=monthvise_high,
    name='high Price',
    marker_color='rgb(0, 153, 204)'
))
fig.add_trace(go.Bar(
    x=monthvise_low.index,
    y=monthvise_low,
    name='low Price',
    marker_color='rgb(255, 128, 0)'
))

fig.update_layout(barmode='group', 
                  title=' Monthwise High and Low price')
fig.show()

names = cycle(['Open Price','Close Price','High Price','Low Price'])

fig = px.line(y_2020, x=y_2020.timestamp, y=[y_2020['open'], y_2020['close'], 
                                          y_2020['high'], y_2020['low']],
             labels={'Timestamp': 'Timestamp','value':' value'})
fig.update_layout(title_text='Analysis chart', font_size=15, font_color='black',legend_title_text='Parameters')
fig.for_each_trace(lambda t:  t.update(name = next(names)))
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)

fig.show()

#EDA
#Visualizing dataset for 2021
y_2021 = data.loc[(data['timestamp'] >= '2021-01-01')
                     & (data['timestamp'] < '2022-01-01')]

y_2021.drop(y_2020[['trades','volume','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

monthvise= y_2021.groupby(y_2021['timestamp'].dt.strftime('%B'))[['open','close']].mean()
new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 
             'September', 'October', 'November', 'December']
monthvise = monthvise.reindex(new_order, axis=0)
monthvise

fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['open'],
    name='Open Price',
    marker_color='crimson'
))
fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['close'],
    name='Close Price',
    marker_color='lightsalmon'
))

fig.update_layout(barmode='group', xaxis_tickangle=-45, 
                  title='Monthwise comparision between open and close price')
fig.show()

y_2021.groupby(y_2021['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_high = y_2021.groupby(data['timestamp'].dt.strftime('%B'))['high'].max()
monthvise_high = monthvise_high.reindex(new_order, axis=0)

monthvise_low = y_2021.groupby(y_2021['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_low = monthvise_low.reindex(new_order, axis=0)

fig = go.Figure()
fig.add_trace(go.Bar(
    x=monthvise_high.index,
    y=monthvise_high,
    name='high Price',
    marker_color='rgb(0, 153, 204)'
))
fig.add_trace(go.Bar(
    x=monthvise_low.index,
    y=monthvise_low,
    name='low Price',
    marker_color='rgb(255, 128, 0)'
))

fig.update_layout(barmode='group', 
                  title=' Monthwise High and Low price')
fig.show()

names = cycle([' Open Price','Close Price',' High Price',' Low Price'])

fig = px.line(y_2021, x=y_2021.timestamp, y=[y_2021['open'], y_2021['close'], 
                                          y_2021['high'], y_2021['low']],
             labels={'Timestamp': 'Timestamp','value':'Stock value'})
fig.update_layout(title_text='Analysis chart', font_size=15, font_color='black',legend_title_text='Parameters')
fig.for_each_trace(lambda t:  t.update(name = next(names)))
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)

fig.show()

#EDA
#Visualizing dataset for 2022
y_2022 = data.loc[(data['timestamp'] >= '2022-01-01')
                     & (data['timestamp'] < '2023-01-07')]

y_2022.drop(y_2022[['trades','volume','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

monthvise= y_2022.groupby(y_2022['timestamp'].dt.strftime('%B'))[['open','close']].mean()
new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 
             'September', 'October', 'November', 'December']
monthvise = monthvise.reindex(new_order, axis=0)
monthvise

fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['open'],
    name='Open Price',
    marker_color='crimson'
))
fig.add_trace(go.Bar(
    x=monthvise.index,
    y=monthvise['close'],
    name='Close Price',
    marker_color='lightsalmon'
))

fig.update_layout(barmode='group', xaxis_tickangle=-45, 
                  title='Monthwise comparision between open and close price')
fig.show()

y_2022.groupby(y_2022['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_high = y_2022.groupby(data['timestamp'].dt.strftime('%B'))['high'].max()
monthvise_high = monthvise_high.reindex(new_order, axis=0)

monthvise_low = y_2022.groupby(y_2022['timestamp'].dt.strftime('%B'))['low'].min()
monthvise_low = monthvise_low.reindex(new_order, axis=0)

fig = go.Figure()
fig.add_trace(go.Bar(
    x=monthvise_high.index,
    y=monthvise_high,
    name='high Price',
    marker_color='rgb(0, 153, 204)'
))
fig.add_trace(go.Bar(
    x=monthvise_low.index,
    y=monthvise_low,
    name='low Price',
    marker_color='rgb(255, 128, 0)'
))

fig.update_layout(barmode='group', 
                  title=' Monthwise High and Low price')
fig.show()

names = cycle(['Open Price',' Close Price','High Price',' Low Price'])

fig = px.line(y_2022, x=y_2022.timestamp, y=[y_2022['open'], y_2022['close'], 
                                          y_2022['high'], y_2022['low']],
             labels={'Timestamp': 'Timestamp','value':'Stock value'})
fig.update_layout(title_text='Analysis chart', font_size=15, font_color='black',legend_title_text='Parameters')
fig.for_each_trace(lambda t:  t.update(name = next(names)))
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)

fig.show()

y_overall=data
y_overall.drop(y_overall[['volume', 'trades','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

monthvise= y_overall.groupby(y_overall['timestamp'].dt.strftime('%B'))[['open','close']].mean()
new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 
             'September', 'October', 'November', 'December']
monthvise = monthvise.reindex(new_order, axis=0)

names = cycle(['Open Price','Close Price','High Price','Low Price'])

fig = px.line(y_overall, x=y_overall.timestamp, y=[y_overall['open'], y_overall['close'], 
                                          y_overall['high'], y_overall['low']],
             labels={'Timestamp': 'TImestamp','value':' value'})
fig.update_layout(title_text='Analysis chart', font_size=15, font_color='black',legend_title_text='Parameters')
fig.for_each_trace(lambda t:  t.update(name = next(names)))
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)

fig.show()

closedf = data[['timestamp','close']]
print("Shape of close dataframe:", closedf.shape)

closedf = closedf[closedf['timestamp'] > '2020-09-13']
close_stock = closedf.copy()
print("Total data for prediction: ",closedf.shape[0])

del closedf['timestamp']
scaler=MinMaxScaler(feature_range=(0,1))
closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))
print(closedf.shape)

def prepare_X_y(data):
    X = data.values
    ind = list(data.columns).index('open')
    y = []
    for i in range(X.shape[0]-1):
        if (X[i+1,ind]-X[i,ind])>0:
            y.append(1)
        else:
            y.append(0)
    y = np.array(y)
    X = X[:-1]
    return y

y = prepare_X_y(data)

prepare_X_y(data)

y

def split_train_test(X,y):
    split_ratio=0.9
    train_size = int(round(split_ratio * X.shape[0]))
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_test = X[train_size:]
    y_test = y[train_size:]

#     print(X_train.shape, y_train.shape)
#     print(X_test.shape, y_test.shape)
    return X_train

def train_model(X_train, y_train):
    model = xgb.XGBClassifier()
    model.fit(X_train, y_train)
    return model
  
def predict(model):
    y_pred = model.predict(X_test)
    y_pred = [round(value) for value in y_pred]
    return y_pred

X = data.drop(['volume', 'trades','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol','timestamp'],axis=1)

X

y

X_train = split_train_test(X,y)
X_train

def split_train_test(X,y):
    split_ratio=0.9
    train_size = int(round(split_ratio * X.shape[0]))
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_test = X[train_size:]
    y_test = y[train_size:]

#     print(X_train.shape, y_train.shape)
#     print(X_test.shape, y_test.shape)
    return y_train

y_train = split_train_test(X,y)
y_train

y_train.shape

model=train_model(X_train, y_train)
model

def split_train_test(X,y):
    split_ratio=0.9
    train_size = int(round(split_ratio * X.shape[0]))
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_test = X[train_size:]
    y_test = y[train_size:]

#     print(X_train.shape, y_train.shape)
#     print(X_test.shape, y_test.shape)
    return X_test

X_test=split_train_test(X,y)
X_test

def split_train_test(X,y):
    split_ratio=0.9
    train_size = int(round(split_ratio * X.shape[0]))
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_test = X[train_size:]
    y_test = y[train_size:]

#     print(X_train.shape, y_train.shape)
#     print(X_test.shape, y_test.shape)
    return y_test

y_test=split_train_test(X,y)
X_test = X_test[:266]

X_test.shape

def predict(model):
    y_pred = model.predict(X_test)
    y_pred = [round(value) for value in y_pred]
    return y_pred

y_pred=predict(model)
# y_pred.shape
y_pred1 = np.array(y_pred)
y_pred1.shape

y_pred1 = np.array(y_pred)

y_pred1

y_test=y_test[:266]

accuracy_score(y_test, y_pred1)

y_test[:266]

f1_score(y_test, y_pred1)

#Loading dataset
data=pd.read_csv("/content/XBTUSD-1d-data.csv")

df = data.drop(data[['open','high','low','trades','volume','vwap','lastSize', 'turnover', 'homeNotional','foreignNotional','symbol']],axis=1)

df

length_data = len(data)     # rows that data has
split_ratio = 0.7           # %70 train + %30 validation
length_train = round(length_data * split_ratio)  
length_validation = length_data - length_train
print("Data length :", length_data)
print("Train data length :", length_train)
print("Validation data lenth :", length_validation)

train_data = df[:length_train].iloc[:,:2] 
train_data['timestamp'] = pd.to_datetime(train_data['timestamp'])  # converting to date time object
train_data

validation_data = df[length_train:].iloc[:,:2]
validation_data['timestamp'] = pd.to_datetime(validation_data['timestamp'])  # converting to date time object
validation_data

"""# Creating Train Dataset from Train split"""

dataset_train = train_data.close.values
dataset_train.shape

# Change 1d array to 2d array
# Changing shape from (1692,) to (1692,1)
dataset_train = np.reshape(dataset_train, (-1,1))
dataset_train.shape

"""# Normalization / Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range = (0,1))


# scaling dataset
dataset_train_scaled = scaler.fit_transform(dataset_train)

dataset_train_scaled.shape

plt.subplots(figsize = (15,6))
plt.plot(dataset_train_scaled)
plt.xlabel("Days as 1st, 2nd, 3rd..")
plt.ylabel("Close Price")
plt.show()

"""# Creating X_train and y_train from Train data"""

X_train = []
y_train = []

time_step = 50

for i in range(time_step, length_train):
    X_train.append(dataset_train_scaled[i-time_step:i,0])
    y_train.append(dataset_train_scaled[i,0])
    
# convert list to array
X_train, y_train = np.array(X_train), np.array(y_train)

print("Shape of X_train before reshape :",X_train.shape)
print("Shape of y_train before reshape :",y_train.shape)

"""# Reshape"""

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))
y_train = np.reshape(y_train, (y_train.shape[0],1))

print("Shape of X_train after reshape :",X_train.shape)
print("Shape of y_train after reshape :",y_train.shape)

X_train[0]

y_train[0]

# importing libraries
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import SimpleRNN
from keras.layers import Dropout

# initializing the RNN
regressor = Sequential()

# adding first RNN layer and dropout regulatization
regressor.add(
    SimpleRNN(units = 50, 
              activation = "tanh", 
              return_sequences = True, 
              input_shape = (X_train.shape[1],1))
             )
regressor.add(
    Dropout(0.2)
             )


# adding second RNN layer and dropout regulatization

regressor.add(
    SimpleRNN(units = 50, 
              activation = "tanh", 
              return_sequences = True)
             )

regressor.add(
    Dropout(0.2)
             )
# adding third RNN layer and dropout regulatization

regressor.add(
    SimpleRNN(units = 50, 
              activation = "tanh", 
              return_sequences = True)
             )

regressor.add(
    Dropout(0.2)
             )

# adding fourth RNN layer and dropout regulatization

regressor.add(
    SimpleRNN(units = 50)
             )
regressor.add(
    Dropout(0.2)
             )

# adding the output layer
regressor.add(Dense(units = 1))

# compiling RNN
regressor.compile(
    optimizer = "adam", 
    loss = "mean_squared_error",
    metrics = ["accuracy"])
batch_size
# fitting the RNN
history = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)

# Evaluating Model

# Losses
history.history["loss"]

# Plotting Loss vs Epochs
plt.figure(figsize =(10,7))
plt.plot(history.history["loss"])
plt.xlabel("Epochs")
plt.ylabel("Losses")
plt.title("Simple RNN model, Loss vs Epoch")
plt.show()

# Plotting Accuracy vs Epochs
plt.figure(figsize =(10,5))
plt.plot(history.history["accuracy"])
plt.xlabel("Epochs")
plt.ylabel("Accuracies")
plt.title("Simple RNN model, Accuracy vs Epoch")
plt.show()

"""Model Prediction for train data

"""

y_pred = regressor.predict(X_train)  # predictions
y_pred = scaler.inverse_transform(y_pred) # scaling back from 0-1 to original
y_pred.shape

y_train = scaler.inverse_transform(y_train) # scaling back from 0-1 to original
y_train.shape

# visualisation
plt.figure(figsize = (21,7))
plt.plot(y_pred, color = "b", label = "y_pred" )
plt.plot(y_train, color = "g", label = "y_train")
plt.xlabel("Days")
plt.ylabel("Close price")
plt.title("Simple RNN model, Predictions with input X_train vs y_train")
plt.legend()
plt.show()

"""Creating Test Dataset from Validation Data


"""

# Converting array and scaling
dataset_validation = validation_data.close.values  # getting "close" column and converting to array
dataset_validation = np.reshape(dataset_validation, (-1,1))  # converting 1D to 2D array
scaled_dataset_validation =  scaler.fit_transform(dataset_validation)  # scaling open values to between 0 and 1
print("Shape of scaled validation dataset :",scaled_dataset_validation.shape)

# Creating X_test and y_test
X_test = []
y_test = []

for i in range(time_step, length_validation):
    X_test.append(scaled_dataset_validation[i-time_step:i,0])
    y_test.append(scaled_dataset_validation[i,0])

# Converting to array
X_test, y_test = np.array(X_test), np.array(y_test)

print("Shape of X_test before reshape :",X_test.shape)
print("Shape of y_test before reshape :",y_test.shape)

"""Reshape"""

X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))  # reshape to 3D array
y_test = np.reshape(y_test, (-1,1))  # reshape to 2D array
socure=65.268

print("Shape of X_test after reshape :",X_test.shape)
print("Shape of y_test after reshape :",y_test.shape)

"""Evaluating with Validation Data"""

# predictions with X_test data
y_pred_of_test = regressor.predict(X_test)
# scaling back from 0-1 to original
y_pred_of_test = scaler.inverse_transform(y_pred_of_test) 
print("Shape of y_pred_of_test :",y_pred_of_test.shape)

# visualisation
plt.figure(figsize = (30,10))
plt.plot(y_pred_of_test, label = "y_pred_of_test", c = "orange")
plt.plot(scaler.inverse_transform(y_test), label = "y_test", c = "g")
plt.xlabel("Days")
plt.ylabel("Close price")
plt.title("Simple RNN model, Prediction with input X_test vs y_test")
plt.legend()
plt.show()

# Visualisation
plt.subplots(figsize =(30,12))
plt.plot(train_data.timestamp, train_data.close, label = "train_data", color = "b")
plt.plot(validation_data.timestamp, validation_data.close, label = "validation_data", color = "g")
plt.plot(train_data.timestamp.iloc[time_step:], y_pred, label = "y_pred", color = "r")
plt.plot(validation_data.timestamp.iloc[time_step:], y_pred_of_test, label = "y_pred_of_test", color = "orange")
plt.xlabel("Days")
plt.ylabel("Close price")
plt.title("Simple RNN model, Train-Validation-Prediction")
plt.legend()
plt.show()

"""Creating LSTM Model"""

y_train = scaler.fit_transform(y_train)

from keras.layers import LSTM

model_lstm = Sequential()
model_lstm.add(
    LSTM(64,return_sequences=True,input_shape = (X_train.shape[1],1))) #64 lstm neuron block
model_lstm.add(
    LSTM(64, return_sequences= False))
model_lstm.add(Dense(32))
model_lstm.add(Dense(1))
model_lstm.compile(loss = "mean_squared_error", optimizer = "adam", metrics = ["accuracy"])
history2 = model_lstm.fit(X_train, y_train, epochs = 10, batch_size = 10)

"""Evaluating LSTM Model"""

plt.figure(figsize =(10,5))
plt.plot(history2.history["loss"])
plt.xlabel("Epochs")
plt.ylabel("Losses")
plt.title("LSTM model, Accuracy vs Epoch")
plt.show()

plt.subplots(figsize =(30,12))
plt.plot(scaler.inverse_transform(model_lstm.predict(X_test)), label = "y_pred_of_test", c = "orange" )
plt.plot(scaler.inverse_transform(y_test), label = "y_test", color = "g")
plt.xlabel("Days")
plt.ylabel("Close price")
plt.title("LSTM model, Predictions with input X_test vs y_test")
plt.legend()
plt.show()

"""Future price prediction"""

data.iloc[-1]

X_input = data.iloc[-time_step:].close.values               # getting last 50 rows and converting to array
X_input = scaler.fit_transform(X_input.reshape(-1,1))      # converting to 2D array and scaling
X_input = np.reshape(X_input, (1,50,1))                    # reshaping : converting to 3D array
print("Shape of X_input :", X_input.shape)
X_input

simple_RNN_prediction = scaler.inverse_transform(regressor.predict(X_input))
LSTM_prediction = scaler.inverse_transform(model_lstm.predict(X_input))
print("Simple RNN, Close price prediction for 3/18/2017      :", simple_RNN_prediction[0,0])
print("LSTM prediction, Close price prediction for 3/18/2017 :", LSTM_prediction[0,0])
simple_RNN_prediction

from sklearn.metrics import r2_score

score = r2_score(y_test, y_pred_of_test)

#y_test

#y_pred_of_test



y_pred = scaler.inverse_transform(y_pred)

y_pred

#y_pred_of_test

y_test = scaler.inverse_transform(y_test)

#y_test

y_pred_of_test  = scaler.inverse_transform(y_pred_of_test)

#y_pred_of_test

socre = r2_score(y_test, y_pred_of_test)

socure

